{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "injured-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('./data_v3.csv')\n",
    "\n",
    "data['bug_num'] = data['bug_num'].map(lambda bnum: bnum - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "overall-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "automotive-incidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:14:33] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:14:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-mlogloss:1.30922\ttrain-mlogloss:1.30438\n",
      "[1]\teval-mlogloss:1.24812\ttrain-mlogloss:1.21831\n",
      "[2]\teval-mlogloss:1.19471\ttrain-mlogloss:1.13699\n",
      "[3]\teval-mlogloss:1.15006\ttrain-mlogloss:1.07048\n",
      "[4]\teval-mlogloss:1.11473\ttrain-mlogloss:1.00944\n",
      "[5]\teval-mlogloss:1.07280\ttrain-mlogloss:0.95941\n",
      "[6]\teval-mlogloss:1.03895\ttrain-mlogloss:0.90856\n",
      "[7]\teval-mlogloss:1.01413\ttrain-mlogloss:0.86908\n",
      "[8]\teval-mlogloss:0.98495\ttrain-mlogloss:0.82829\n",
      "[9]\teval-mlogloss:0.96564\ttrain-mlogloss:0.79065\n",
      "[10]\teval-mlogloss:0.93663\ttrain-mlogloss:0.75608\n",
      "[11]\teval-mlogloss:0.92251\ttrain-mlogloss:0.72106\n",
      "[12]\teval-mlogloss:0.89954\ttrain-mlogloss:0.69080\n",
      "[13]\teval-mlogloss:0.88407\ttrain-mlogloss:0.66102\n",
      "[14]\teval-mlogloss:0.86908\ttrain-mlogloss:0.64133\n",
      "[15]\teval-mlogloss:0.85126\ttrain-mlogloss:0.61896\n",
      "[16]\teval-mlogloss:0.83931\ttrain-mlogloss:0.59659\n",
      "[17]\teval-mlogloss:0.82700\ttrain-mlogloss:0.57600\n",
      "[18]\teval-mlogloss:0.82030\ttrain-mlogloss:0.55814\n",
      "[19]\teval-mlogloss:0.81034\ttrain-mlogloss:0.54179\n",
      "[20]\teval-mlogloss:0.80534\ttrain-mlogloss:0.52544\n",
      "[21]\teval-mlogloss:0.80025\ttrain-mlogloss:0.51040\n",
      "[22]\teval-mlogloss:0.78981\ttrain-mlogloss:0.49468\n",
      "[23]\teval-mlogloss:0.79043\ttrain-mlogloss:0.48106\n",
      "[24]\teval-mlogloss:0.78881\ttrain-mlogloss:0.46481\n",
      "[25]\teval-mlogloss:0.78368\ttrain-mlogloss:0.45105\n",
      "[26]\teval-mlogloss:0.77932\ttrain-mlogloss:0.43683\n",
      "[27]\teval-mlogloss:0.77909\ttrain-mlogloss:0.42443\n",
      "[28]\teval-mlogloss:0.78008\ttrain-mlogloss:0.41392\n",
      "[29]\teval-mlogloss:0.78572\ttrain-mlogloss:0.39984\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "created_at,\n",
    "updated_at,\n",
    "size,\n",
    "stargazers_count,\n",
    "watchers_count, #\n",
    "forks_count, #\n",
    "network_count, #\n",
    "subscribers_count, #\n",
    "followers, #\n",
    "public_repos, #\n",
    "created_at,\n",
    "contributions, #\n",
    "author_id,\n",
    "LOC, #\n",
    "Add, #\n",
    "Delete, #\n",
    "Files, #\n",
    "bug_num  #\n",
    "'''\n",
    "\n",
    "feature_columns = [\n",
    "    #'watchers_count',\n",
    "    #'forks_count',\n",
    "    #'network_count',\n",
    "    #'subscribers_count',\n",
    "    'followers',\n",
    "    'public_repos',\n",
    "    'contributions',\n",
    "    'LOC',\n",
    "    'Add',\n",
    "    'Delete',\n",
    "    'Files',\n",
    "]\n",
    "\n",
    "target_column = 'bug_num'\n",
    "\n",
    "\n",
    "xgtrain = xgb.DMatrix(train[feature_columns].values, train[target_column].values)\n",
    "xgtest = xgb.DMatrix(test[feature_columns].values, test[target_column].values)\n",
    "\n",
    "\n",
    "param = {\n",
    "    'max_depth':5,\n",
    "    'eta':0.1,\n",
    "    'silent':1,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'objective':'multi:softmax',\n",
    "    'num_class': 4, \n",
    "}\n",
    "\n",
    "# build the model\n",
    "watchlist  = [(xgtest,'eval'), (xgtrain,'train')]\n",
    "num_round = 30\n",
    "bst = xgb.train(param, xgtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eleven-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error0.400000\n"
     ]
    }
   ],
   "source": [
    "# prediction and check the accuracy\n",
    "preds = bst.predict(xgtest)\n",
    "labels = xgtest.get_label()\n",
    "print ('error%f' % \\\n",
    "       (sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-headset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
